## ho copiato lo script x analisi oncogenes TSG from USER, ora lo riapplico a USER=1


library(tidyverse)
library(readxl)
library(dplyr)
library(ggplot2)
library(ggsignif)
library(data.table)
library(writexl)
library(tidyr)
library(cowplot)
library(grid)
options(dplyr.summarise.inform = FALSE)

`%!in%` <- Negate(`%in%`)

## define default datasets: 

## global distance table, as generated by the function:

file_dist_glob_pathway_part1 <- readRDS('./input_tables/GlobalDistance_Pathways/file_dist_glob_pathway_part1.rds')
file_dist_glob_pathway_part2 <- readRDS('./input_tables/GlobalDistance_Pathways/file_dist_glob_pathway_part2.rds')

file_dist_glob_pathway <- rbind(file_dist_glob_pathway_part1, file_dist_glob_pathway_part2)

###define background for the paths, by default it consists in the entire SIGNOR proteome: 

signor_data_original = as.data.frame(fread(paste0('https://signor.uniroma2.it/getData.php?'), header=F))

proteinsA = signor_data_original$V1[which(signor_data_original$V2=='protein')]

proteinsB = signor_data_original$V5[which(signor_data_original$V6=='protein')]

all.signor.id = c(proteinsA,proteinsB)

all.signor.id <- unique(all.signor.id)

all.signor.id

ProxPath_Pathways_parse_distance_table <- function (
    distance_file = file_dist_glob_pathway, ## output of
    expansion = TRUE,
    background = all.signor.id,
    default_min = 0.000001,
    statistic_zcore = 'mean',
    zcore_threshold= -2.58,
    save_directory){
  
  print ('Pathway global table parsing might take 5-10 mins')
  
  default_max = ceiling(max(distance_file$Path_Score))
  
  if (expansion == TRUE){
    
    table.parsing <- distance_file[0,]
    
    distance_file$pathkey<- paste0(distance_file$QueryNode,'|',
                                   distance_file$EndNode, '|',
                                   distance_file$EndPathways)
    
    all_target <- unique(paste0(distance_file$EndNode,'|', distance_file$EndPathways))
    
    expand.grid(background, all_target ) -> table.parsing
    
    colnames(table.parsing) <- c("QueryNode", "pathway.key")
    
    separate(table.parsing, col = pathway.key, sep = '\\|', into= c('EndNode', 'EndPathways')) ->table.parsing
    
    table.parsing$Path_String ='-'
    
    table.parsing$relations_path ='-'
    
    table.parsing$Path_Score = default_max
    
    table.parsing$Path_Length = 5
    
    table.parsing$Final_Effect = NA
    
    table.parsing$pathkey<- paste0(table.parsing$QueryNode,'|',
                                   table.parsing$EndNode, '|',
                                   table.parsing$EndPathways)
    
    table.parsing %>%
      dplyr::filter (pathkey %!in%  distance_file$pathkey)%>%
      dplyr::select(-pathkey)-> table.parsing
    
    table.parsing <- rbind(table.parsing,distance_file[,1:8])
  } else {
    ### if you want to skip expansion of nodes in INPUT
    table.parsing <- distance_file[,1:8]
    background <- unique(table.parsing$QueryNode)
  }
  
  table.parsing %>%
    distinct(Path_String, QueryNode, EndNode, EndPathways, .keep_all = TRUE)-> table.parsing
  
  table.parsing -> table.input
  
  table.input$Effect <- '-'
  
  table.input$Effect[ table.input$Final_Effect == 1] <- '-'
  
  table.input$Effect[ table.input$Final_Effect == 0] <- '-'
  
  table.input$Effect[ table.input$Final_Effect == -1] <- '-'
  
  table.input$Effect[ table.input$Path_Length == 0] <- '-'
  
  table.input$Path_Score[ table.input$Path_Length == 0] <- default_min
  
  ##distribution over the target phenotype
  
  table.input$Path_Score <- as.numeric(table.input$Path_Score)
  table.input$Path_Score[ table.input$Path_Length == 0] <- default_min
  if (statistic_zcore == 'mean'){
    
    table.input%>%
      group_by(EndPathways)%>% 
      reframe(n = n(), 
              mean = mean(Path_Score), 
              sd=sd(Path_Score)) -> table.mean.sd
    
    table.input <- merge(x = table.input, y = table.mean.sd, by = c('EndPathways'), all.x = TRUE)
    
    
    table.input$zscore <- (table.input$Path_Score - table.input$mean)/table.input$sd
  } else if(statistic_zcore == 'median'){
    
    table.input%>%
      group_by(EndPathways)%>% ####Effect
      reframe(n = n(), 
              mean = median(Path_Score), 
              sd=sd(Path_Score)) -> table.mean.sd
    
    table.input <- merge(x = table.input, y = table.mean.sd, by = c('EndPathways'), all.x = TRUE)
    
    
    table.input$zscore <- (table.input$Path_Score - table.input$mean)/table.input$sd
  }
  table.input%>%  
    dplyr::filter(zscore <= zcore_threshold)  -> table.zscore.filtered
  
  write_tsv(table.zscore.filtered, paste0(save_directory, 'significant_paths_to_phenotypes.txt'))
  
  
  return (table.zscore.filtered)
}  


ProxPath_Pathways_enrichment <- function (
    save_tables = FALSE,
    analysis_name,
    parsed_distance_file_phenotypes, ## output of ProxPath_Phenotypes_parse_distance_table function
    input_list,
    background = all.signor.id,
    correction_method = 'BH',
    pvalue_threshold = 0.05,
    save_directory,
    num_randomization = 1000){
  
  analysis_name=paste0(analysis_name,'_to_Pathway')
  
  ### parsed_distance_file contains z_score filtered paths generated by ProxPath_Phenotypes_parse_distance_table function
  
  parsed_distance_file_phenotypes %>%
    distinct(Path_String, QueryNode, EndNode, EndPathways, .keep_all = TRUE) -> table.zscore.filtered.slim
  
  
  ## analyse all the datasets:
  table.zscore.filtered.slim%>%
    dplyr::group_by(EndPathways, Effect)%>%
    dplyr::summarise(total = n()) -> effect.total
  
  # ##check for the correctness of each input dataset
  for (list_i in input_list){
    list_i = gsub('-','.',list_i)
    dataset_i <- eval(parse(text = list_i))
    USER_dataset <- data.frame(dataset_i)}
  
  ##run the analysis for  each input dataset
  for (list_i in input_list){
    list_i = gsub('-','.',list_i)
    dataset_i <- eval(parse(text = list_i))
    
    USER_dataset <- data.frame(dataset_i)
    colnames(USER_dataset)[1] <- "QueryNode"
    print(list_i)
    dim_datset = dim(unique(USER_dataset))[1]
    
    # ## start analysis to search for significant paths to up/down regulations of pathways/RLE
    table.final.rand <- data.frame(matrix (ncol = 4, nrow = 0))
    colnames(table.final.rand) <- c( "EndPathways",
                                     "Effect",
                                     "hits",
                                     "total" )
    
    # Create a base df with all 0s if it doesn't find a target
    base_df <- dplyr::bind_rows(tidyr::tibble(EndPathways = unique(table.zscore.filtered.slim$EndPathways), Effect = 'down-regulates', hits = 0, total = 0),
                                tidyr::tibble(EndPathways = unique(table.zscore.filtered.slim$EndPathways), Effect = 'up-regulates', hits = 0, total = 0))
    
    print(paste0('Start randomization of ', list_i, ' network...'))
    #### comincia ciclo for da qui per la randomizzazione
    for (i in c(1:num_randomization)){
      random_genes <- sample(background)[1:dim_datset]
      
      table.zscore.filtered.slim%>%
        dplyr::filter(QueryNode %in% random_genes) %>%
        dplyr::group_by(EndPathways, Effect)%>%
        dplyr::reframe(hits = n()) -> table.randomized
      
      randomized <- merge(x= table.randomized, 
                          y= effect.total, 
                          by = c('EndPathways', 'Effect'),
                          all.x = T)
      
      base_df_anti <- anti_join(base_df, randomized, by = c('EndPathways', 'Effect'))
      
      randomized <- rbind(randomized, base_df_anti)
      
      table.final.rand<- rbind(table.final.rand, randomized)
    }
    
    table.final.rand$Frac_rand <- table.final.rand$hits/table.final.rand$total
    
    table.final.rand$Frac_rand[is.nan(table.final.rand$Frac_rand)] <- 0
    
    table.final.rand %>%
      dplyr::group_by(EndPathways, Effect)%>%
      dplyr::reframe(mean = mean(Frac_rand), 
                     sd = sd(Frac_rand), 
                     min = min(Frac_rand), 
                     max = max(Frac_rand)) -> table.final.rand.sd.mean
    
    
    #### analysis of the USER-provided dataset
    
    table.zscore.filtered.slim%>%
      dplyr::filter(QueryNode %in% USER_dataset$QueryNode) %>%
      dplyr::group_by(EndPathways, Effect)%>%
      dplyr::reframe(hits = n()) -> table.USER
    
    table.USER <- merge(x= table.USER, 
                        y= effect.total, 
                        by = c('EndPathways', 'Effect'),
                        all.x = T)
    
    colnames(table.USER) <- c("EndPathways", "Effect", "hits_USER", "total_paths_impacting_phenotype" )
    
    table.USER$Fraction <- round(table.USER$hits_USER/table.USER$total_paths_impacting_phenotype, 3)
    
    output.table <- merge(x= table.USER, 
                          y= table.final.rand.sd.mean, 
                          by = c('EndPathways', 'Effect'),
                          all.x = T)
    
    #### parte con p-value calcolato con t-score
    
    output.table$t <- (output.table$Fraction-output.table$mean)/output.table$sd
    
    output.table$pvalue_raw <- pnorm(output.table$t, 
                                     lower.tail = FALSE)
    
    output.table$list_name <- list_i
    
    if (!exists("output.table.global")){
      output.table.global <- output.table
    } else {
      output.table.global <- rbind(output.table.global, output.table)
    }
  }
  
  ## address data statistical significance
  
  output.table.global -> output.table.global.stat
  
  output.table.global.stat$pvalue <- p.adjust(output.table.global.stat$pvalue_raw, method = correction_method, n = length(output.table.global.stat$EndPathways))
  
  output.table.global.stat$sign <- ''
  
  output.table.global.stat$sign[output.table.global.stat$pvalue < 0.05]<- '*'
  
  output.table.global.stat$sign[output.table.global.stat$pvalue < 0.001]<- '**'
  
  output.table.global.stat$sign[output.table.global.stat$pvalue < 0.0001]<- '***'
  
  output.table.global.stat$sign[output.table.global.stat$pvalue < 0.00001]<- '****'
  
  output.table.global.stat$sign[output.table.global.stat$pvalue >1 ]<- '!'
  
  
  ### SAVE ANLYSIS DATA
  
  output.table.global.stat %>%
    filter( pvalue < pvalue_threshold) -> output.table.global.stat
  output.table.global.stat-> output.table.global.stat.general
  # 
  # output.table.global.stat.general$EndPathways <- sapply(strsplit(as.character(output.table.global.stat.general$EndPathways ), "="),"[", 1) 
  # 
  write_xlsx(
    output.table.global.stat.general,
    path =paste0(save_directory, "randomization_",analysis_name,".xlsx"),
    col_names = TRUE,
    format_headers = TRUE,
    use_zip64 = FALSE)
  if (save_tables == TRUE){  
    # ### display interactions from USER genes to phenotypes
    
    id_table <- data.frame(matrix (ncol = 3, nrow = 0))
    
    colnames(id_table) <- c( "analysis",
                             "list_name",
                             "signor_ids")
    
    plot_list <- vector("list",2)
    
    i = 1
    
    for (list_i in input_list){
      
      print(paste0('saving plot and table of ', list_i, '...'))
      
      list_i = gsub('-','.',list_i)
      
      print(list_i)
      
      dataset_i <- eval(parse(text = list_i))
      
      output.table.global.stat%>%
        filter(list_name == list_i)-> output.table.global.stat_filtered
      
      table.zscore.filtered.slim$EndPathways <- as.character(table.zscore.filtered.slim$EndPathways)
      
      table.zscore.filtered.slim$QueryNode <- as.character(table.zscore.filtered.slim$QueryNode)
      
      table.zscore.filtered.slim%>%
        filter(QueryNode %in% dataset_i & EndPathways %in% output.table.global.stat_filtered$EndPathways)-> USER.Phen.Paths
      
      ##print interaction ids for all pathways (alltogether)
      USER.Phen.Paths %>%
        separate_rows(relations_path,  sep= ';', convert = TRUE)%>%
        na.omit()-> USER.Phen.Paths.temp
      
      int_ids_temp <- unique(USER.Phen.Paths.temp$relations_path)
      
      int_ids_ALL <- paste(int_ids_temp, collapse = ' ')
      
      id_table_temp = data.frame("analysis" = analysis_name,
                                 "list_name" = list_i,
                                 "signor_ids"= int_ids_ALL)
      
      id_table <- rbind(id_table, id_table_temp)
      
      # prepare data for plotting
      output.table.global.stat_filtered$Log10_p_value_plot <- -log10(output.table.global.stat_filtered$pvalue)
      
      output.table.global.stat_filtered%>%
        arrange(as.integer(Log10_p_value_plot))%>%
        arrange(Effect)%>%
        mutate(EndPathways = tolower(gsub('_', ' ', EndPathways)))%>%
        as_tibble() -> output.table.global.stat.general.plot #%>% distinct(EndPathways, .keep_all = T)
      
      output.table.global.stat.general.plot$EndPathways<- factor(output.table.global.stat.general.plot$EndPathways, levels=output.table.global.stat.general.plot$EndPathways)
      
      ggplot(output.table.global.stat.general.plot, aes(x = factor(EndPathways), y = Log10_p_value_plot, fill = Effect)) +
        # geom_bar( stat = 'identity')+
        geom_col(position = "dodge")+
        ggtitle(paste0('Significantly close phenotypes - ' , list_i)) +
        ylab("-Log10(p-value)") + xlab('phenotype') +
        
        theme_bw()+
        scale_fill_manual(values = c("orange"))+
        geom_text(aes(label = hits_USER), colour = "black", size = 2, hjust= 1, position = position_dodge(.9))+
        coord_flip()->plot_1
      plot_1
      plot_list[[i]]<- plot_1
      i = i+1
      
      # ## SAVE ID TABLE AND PLOT
      write_xlsx(
        id_table,
        path =paste0(save_directory, "signorID_",analysis_name,".xlsx"),
        col_names = TRUE,
        format_headers = TRUE,
        use_zip64 = FALSE)
      
      combined_plots <- plot_grid(plotlist = plot_list, labels = "AUTO", ncol=1)
      
      ggsave(paste0(save_directory, analysis_name, '_plot.pdf'), device= 'pdf', plot = combined_plots, height = 40, width =20, units = 'cm')
    }
    return(output.table.global.stat)
  }
}
